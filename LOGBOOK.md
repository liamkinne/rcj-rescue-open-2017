# Logbook / Journal Entry: Vector

## Background
I've had an odd start with RoboCup Junior, often doing things the wrong way round. The first year I was directly involved with the competition it was 2015, I was 15 and I was mentoring a team of primary school students for UTAS Robotics, a robotics club which I had help found earlier that year. This team was performing so well that they entered in secondary rescue (because they found primary rescue too easy), placing first in the Hobart regionals and third in the state finals. In 2016 as well as mentoring another two teams, I competed by myself in the Hobart regionals with an Arduino/NXT hybrid robot in secondary rescue. This robot was originally just a proof of concept that I'd built a few days before the competition, but I ended up entering it and taking home first place. This robot had two advantages over it's competitors, the lightweight code design which had sensors being polled and motors being update about four times faster than an NXT or EV3 could, and the fact that it used proportional line follow (outlined in a tutorial on my website (http://liamkinne.com/2017/line-follow-done-right/). Annoyingly I didn't bother entering that robot when I went to the national open mainly I was busy with in the open soccer team I was on and because I thought national level rescue would be a lot harder than it was.

## Design and Inspiration
In my robotics class that I am now doing in college, one of my projects was building a robot arm that could be used by someone who either had lost use of their arm and didn't have one. Most other members of my class went for arms that were as similar to human arms as possible, but I wanted mine to be better than a human arm and in some kind of way, unique. What I made is a mechanism that can both grab items and rotate without any limit to rotation. This means that someone using the arm could for example close at tap in one long rotation rather than many small ones among other things. This design which is also featured on my website (http://liamkinne.com/2017/lego-ev3-robotic-hand-challenge/), is the direct inspiration for how I approached getting the Can on-top of the platform in the chemical spill. Instead of lifting the can linearly, my robot is designed to grab the can by the top and spin it 180 degrees thus clearing the height of the platform. Because of the unorthodox nature of this approach, I had to read into the rules quite a lot. I noticed that the rules state that the victim Can must be "placed in an upright, top-up position", which is a problem because when I spin the Can it is upside down. I explained this problem to a few people in my robotics class and most of them agreed with me that I would have to completely revise my deign because it didn't work. Just before I was about to de-construct the test rig I had built, a student suggested the brilliant idea that once I had the can I would just perform the pick-up-spin operation twice. Essentially the robot picks the can up, drops it in its upside-down orientation and then picks it up a second time now In the right orientation. I'm very glad that this student who I didn't even know that well at the time made that suggestion, otherwise my robot would be vastly different in design and not as cool.

## Failed Design Attempts
Something I always like doing is trying a new things with robots to try and make them more efficient. Something I have been having a play with recently was the Pixy vision cam. It is an embedded solution to vision processing that works on anything from your laptop to even EV3 bricks and seemed perfect for tracking objects like green turn markers, victim Cans and red platforms. I wanted to get this system working before the state competition, but ran into reliability troubles when testing it. The issue is that cameras have a lot of noise which can make the output of the vision processing very jittery which makes for a difficult time when you're trying to pinpoint the location of an object. This is why, in the end, I had to settle for using just a third light sensor for Can color detection, rather than a fancy Pixy cam. Even the design I have right now isn't perfect and relies on the help of some hot-glued LEGO bits to keep it from falling apart. Other things like weight distribution have also been a problem, but with some extra ballast I've recently added, they should all be working fine now.